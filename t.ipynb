{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.8.0-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python38064bitedavizpipenv8b133a94a5e949ceb4bbb30ea059e9e1",
   "display_name": "Python 3.8.0 64-bit ('edaviz': pipenv)"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST SUR  NOTEBOOK\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import edaviz"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Jeu test  --- TITANIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 887 entries, 0 to 886\nData columns (total 8 columns):\nSurvived                   887 non-null int64\nPclass                     887 non-null int64\nName                       887 non-null object\nSex                        887 non-null object\nAge                        887 non-null float64\nSiblings/Spouses Aboard    887 non-null int64\nParents/Children Aboard    887 non-null int64\nFare                       887 non-null float64\ndtypes: float64(2), int64(4), object(2)\nmemory usage: 55.6+ KB\n"
    }
   ],
   "source": [
    "BASE = os.path.abspath('.')\n",
    "BASE_DIR = os.path.dirname(BASE)\n",
    "dataset = pd.read_csv(os.path.join(BASE, \"tests\", \"titanic.csv\"))\n",
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "age = dataset.Age\n",
    "fare = dataset.Fare\n",
    "survived = dataset.Survived\n",
    "sex = dataset.Sex"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Transformation test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Help on module edaviz.transformations in edaviz:\n\nNAME\n    edaviz.transformations\n\nDESCRIPTION\n    Module centré sur le preprocessing d'un jeu de données.\n    Bien que basé sur un projet d'analyse de données spécifique (OpenFoodFacts),\n    le contenu a pour vocation d'être générique.\n\nFUNCTIONS\n    calculer_imputation(tableau, strategie='première occurence', valeur_par_defaut=None)\n        Imputer suivant la strategie choisie.\n        \n        Arguments d'entrée:\n            tableau (pandas.DataFrame)\n            strategie (str):\n                'première occurence' retourne la première valeur non nulle,\n                'la plus fréquente' retourne la valeur la plus fréquente non nulle\n        \n        Arguments de sortie:\n            tableau_nettoye (pandas.DataFrame)\n    \n    eliminer_colonne_vide(tableau, taux_de_vide_minimum=0.5, retourner_details=True, chemin_fichier='barh_classement_colonnes_vides.png')\n        Supprimer les colonnes avec un taux de remplissage inférieur à une référence donnée.\n        \n        Arguments d'entrée:\n            tableau (pandas.DataFrame)\n            taux_de_vide_minimum (float): au delà de ce taux, la colonne sera considérée vide\n            retourner_details (bool): si True, renvoie le classement des colonnes\n                sur leurs taux de remplissage.\n        \n        Arguments de sortie:\n            tableau_nettoye (pandas.DataFrame)\n            classement (pandas.DataFrame)\n    \n    eliminer_doublons(tableau, colonnes_ciblees=None, strategie='première occurence')\n        Retourne un tableau avec des individus uniques\n        basés sur les colonnes ciblées.\n        \n        Arguments d'entrée:\n            tableau (pandas.DataFrame)\n            colonnes_ciblees (list)\n            strategie (str): méthode pour trouver l'unique individu\n        \n        Arguments de sortie:\n            tableau_nettoye (pandas.DataFrame)\n    \n    eliminer_ligne_vide(tableau, taux=None, retourner_details=True)\n        Supprimer les lignes avec un taux de remplissage inférieur à une référence donnée.\n        \n        Arguments d'entrée:\n            tableau (pandas.DataFrame)\n            taux (float)\n            retourner_details (bool): si True, renvoie le classement des colonnes\n                sur leurs taux de remplissage.\n        \n        Arguments de sorties:\n            tableau_nettoye (pandas.DataFrame)\n            classement (pandas.DataFrame)\n    \n    plus_frequente_occurence(vecteur, valeur_par_defaut=None)\n        Wrapper de la méthode first_valid_index d'un Pandas.Series.\n        \n        Arguments d'entrée:\n            vecteur (pandas.Series)\n            valeur_par_defaut\n        Arguments de sortie:\n            (Python Object)\n    \n    premiere_occurence(vecteur, valeur_par_defaut=None)\n        Wrapper de la méthode first_valid_index d'un Pandas.Series.\n        \n        Arguments d'entrée:\n            vecteur (pandas.Series)\n            valeur_par_defaut\n        Arguments de sortie:\n            (Python Object)\n    \n    trouver_valeur_par_défaut(valeur_par_defaut, clef)\n        Permet de personnaliser une valeur par défaut suivant un axe.\n\nFILE\n    /Users/jortoh/Desktop/Projects/edaviz/edaviz/transformations.py\n\n\n"
    }
   ],
   "source": [
    "from edaviz import transformations as tr\n",
    "help(tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "clst df:\n                     colonne  taux_de_vide\n0                 Survived           0.0\n1                   Pclass           0.0\n2                     Name           0.0\n3                      Sex           0.0\n4                      Age           0.0\n5  Siblings/Spouses Aboard           0.0\n6  Parents/Children Aboard           0.0\n7                     Fare           0.0\n"
    },
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Survived</th>\n      <th>Pclass</th>\n      <th>Name</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>Siblings/Spouses Aboard</th>\n      <th>Parents/Children Aboard</th>\n      <th>Fare</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>3</td>\n      <td>Mr. Owen Harris Braund</td>\n      <td>male</td>\n      <td>22.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>7.2500</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>1</td>\n      <td>Mrs. John Bradley (Florence Briggs Thayer) Cum...</td>\n      <td>female</td>\n      <td>38.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>71.2833</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>3</td>\n      <td>Miss. Laina Heikkinen</td>\n      <td>female</td>\n      <td>26.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>7.9250</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>1</td>\n      <td>Mrs. Jacques Heath (Lily May Peel) Futrelle</td>\n      <td>female</td>\n      <td>35.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>53.1000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>3</td>\n      <td>Mr. William Henry Allen</td>\n      <td>male</td>\n      <td>35.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>8.0500</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>882</th>\n      <td>0</td>\n      <td>2</td>\n      <td>Rev. Juozas Montvila</td>\n      <td>male</td>\n      <td>27.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>13.0000</td>\n    </tr>\n    <tr>\n      <th>883</th>\n      <td>1</td>\n      <td>1</td>\n      <td>Miss. Margaret Edith Graham</td>\n      <td>female</td>\n      <td>19.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>30.0000</td>\n    </tr>\n    <tr>\n      <th>884</th>\n      <td>0</td>\n      <td>3</td>\n      <td>Miss. Catherine Helen Johnston</td>\n      <td>female</td>\n      <td>7.0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>23.4500</td>\n    </tr>\n    <tr>\n      <th>885</th>\n      <td>1</td>\n      <td>1</td>\n      <td>Mr. Karl Howell Behr</td>\n      <td>male</td>\n      <td>26.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>30.0000</td>\n    </tr>\n    <tr>\n      <th>886</th>\n      <td>0</td>\n      <td>3</td>\n      <td>Mr. Patrick Dooley</td>\n      <td>male</td>\n      <td>32.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>7.7500</td>\n    </tr>\n  </tbody>\n</table>\n<p>887 rows × 8 columns</p>\n</div>",
      "text/plain": "     Survived  Pclass                                               Name  \\\n0           0       3                             Mr. Owen Harris Braund   \n1           1       1  Mrs. John Bradley (Florence Briggs Thayer) Cum...   \n2           1       3                              Miss. Laina Heikkinen   \n3           1       1        Mrs. Jacques Heath (Lily May Peel) Futrelle   \n4           0       3                            Mr. William Henry Allen   \n..        ...     ...                                                ...   \n882         0       2                               Rev. Juozas Montvila   \n883         1       1                        Miss. Margaret Edith Graham   \n884         0       3                     Miss. Catherine Helen Johnston   \n885         1       1                               Mr. Karl Howell Behr   \n886         0       3                                 Mr. Patrick Dooley   \n\n        Sex   Age  Siblings/Spouses Aboard  Parents/Children Aboard     Fare  \n0      male  22.0                        1                        0   7.2500  \n1    female  38.0                        1                        0  71.2833  \n2    female  26.0                        0                        0   7.9250  \n3    female  35.0                        1                        0  53.1000  \n4      male  35.0                        0                        0   8.0500  \n..      ...   ...                      ...                      ...      ...  \n882    male  27.0                        0                        0  13.0000  \n883  female  19.0                        0                        0  30.0000  \n884  female   7.0                        1                        2  23.4500  \n885    male  26.0                        0                        0  30.0000  \n886    male  32.0                        0                        0   7.7500  \n\n[887 rows x 8 columns]"
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = tr.eliminer_colonne_vide(dataset, retourner_details=False)\n",
    "test\n",
    "# si rien ne pas faire de graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "l'argument colonnes_ciblees n'est pas de type list mais <class 'NoneType'>\n<class 'pandas.core.frame.DataFrame'>\nInt64Index: 887 entries, 0 to 886\nData columns (total 8 columns):\nSurvived                   887 non-null int64\nPclass                     887 non-null int64\nName                       887 non-null object\nSex                        887 non-null object\nAge                        887 non-null float64\nSiblings/Spouses Aboard    887 non-null int64\nParents/Children Aboard    887 non-null int64\nFare                       887 non-null float64\ndtypes: float64(2), int64(4), object(2)\nmemory usage: 62.4+ KB\n"
    }
   ],
   "source": [
    "unique_data = tr.eliminer_doublons(tableau=dataset, colonnes_ciblees=None, strategie='première occurence')\n",
    "unique_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Correlation test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Help on module edaviz.correlations in edaviz:\n\nNAME\n    edaviz.correlations\n\nDESCRIPTION\n    Fonctions permettant de calculer les différentes corrélations\n    entre les variables d'un même jeu de données.\n    Un vecteur peut être une liste, un Pandas.Series ou NumPy.array.\n\nFUNCTIONS\n    calculer_correlation_pearson(variable_1, variable_2)\n        Calcul de la correlation entre deux variables quantitatives.\n        On retourne donc une valeur entrez 0 et 1.\n        \n        Arguments d'entrée:\n            variable_1, variable_2 (numpy.array)\n        \n        Arguments de sortie:\n            (float)\n    \n    calculer_covariance(variable_1, variable_2)\n        Calcul de la covariance empirique entre deux variables quantitatives.\n        \n        Arguments d'entrée:\n            variable_1, variable_2 (numpy.array)\n        \n        Arguments de sortie:\n            (float)\n    \n    calculer_tableau_contingence(variable_1, variable_2, nom_1=None, nom_2=None, rajouter_colonne_total=False)\n        Calcul du tableau de contingence entre deux variables qualitatives.\n        Basé sur https://openclassrooms.com/fr/courses/4525266-decrivez-et-nettoyez-votre-jeu-de-donnees/4775616-analysez-deux-variables-qualitatives-avec-le-chi-2\n        \n        \n        Arguments d'entrées:\n            variable_1, variable_2 (numpy.array)\n            nom_1, nom_2 (str)\n        \n        Arguments de sortie:\n            tableau_de_contingence (NumPy.array)\n    \n    matrice_de_correlation(tableau, format_compact=True, calculer_autocorrelation=False, retourner_liste=False, *args, **kwargs)\n        Pour calculer la matrice de correlation d'un jeu de données.\n        \n        Arguments d'entrée:\n            tableau (Pandas.DataFrame)\n            format_compact (bool): Si Vrai, matrice de triplet sinon trois matrices en sortie\n            calculer_autocorrelation (bool): Si Vrai, calculer l'autocorrelation qui doit s'annuler\n                #TO FIX à supprimer, peut-être inutile\n            retourner_liste (bool): Si vrai retourner une liste\n                #TO FIX à supprimer, peut-être inutile\n        \n        Arguments de sortie:\n            correlation or correlation_statistique, correlation_p_valeur, correlation_coefficient (NumPy.array or list)\n    \n    matrice_de_significativite(tableau, alpha, retourner_booleen=False, tolerance=0.01, *args, **kwargs)\n        Retourne une matrice où chaque valeur sera comprise entre 0 et 1 ou sera booléenne.\n        \n        Arguments d'entrée:\n                correlation_p_valeur (Numpy.array or list)\n                alpha (float)\n                retourner_booleen (bool)\n                tolerance (float)\n        \n        \n            Arguments de sortie:\n                tableau_de_taille (Numpy.array)\n    \n    normaliser_significativite_booleen(p_valeur, alpha, tolerance, *args, **kwargs)\n        Retourne une valeur booléenne pour qualifier la significativité d'un test statistique.\n        \n        Arguments d'entrée:\n            p_valeur, alpha, tolerance (float)\n        \n        \n        Arguments de sortie:\n            significativite (bool)\n    \n    normaliser_significativite_numerique(p_valeur, alpha, tolerance, *args, **kwargs)\n        Retourne une valeur entre 0 et 1 pour quantifier la significativité d'un test statistique.\n        \n        Arguments d'entrée:\n            p_valeur, alpha, tolerance (float)\n        \n        \n        Arguments de sortie:\n            significativite (float)\n    \n    test_correlation_chi_squared(variable_1, variable_2, nom_1=None, nom_2=None, contingence=None, **kwargs)\n        Test de corrélation du chi-deux\n        pour une corrélation entre deux variables qualtitatives.\n        \n        Arguments d'entrées:\n            variable_1, variable_2 (NumPy.array)\n            nom_1, nom_2 (str)\n            contingence (Python function): function pour calculer un tableau de contingence entre deux variables.\n        \n        Arguments de sorties:\n            statistique, p_valeur, coefficient (float): coefficient basé sur le coefficient de Cramer\n    \n    test_correlation_eta_squared(variable_quantitative, variable_qualitative)\n        Test de corrélation de eta squared\n        pour une corrélation entre une variable quantitative et une variable qualitative.\n        \n        Arguments d'entrées:\n            variable_quantitative, variable_qualitative (NumPy.array)\n        \n        Arguments de sorties:\n            statistique, p_valeur, coefficient (float)\n    \n    test_correlation_pearson(variable_1, variable_2, covariance=None)\n        Test de corrélation de Pearson\n        pour une corrélation entre deux variables quantitatives.\n        \n        Arguments d'entrées:\n            variable_1, variable_2 (NumPy.array)\n            covariance (Python function): function pour calculer une covariance entre deux variables.\n        \n        Arguments de sorties:\n            statistique, p_valeur, coefficient (float)\n    \n    test_de_correlation(variable_1, variable_2, nom_1=None, nom_2=None, seuil_categorie=None, *args, **kwargs)\n        Pour calculer la correlation variables.\n        \n        Arguments d'entrée:\n            variable_1, variable_2 (pandas.Series)\n            nom_1, nom_2 (str)\n        \n        Arguments de sortie:\n            statistique, p_valeur, coefficient (float)\n\nDATA\n    __warningregistry__ = {'version': 94, ('invalid value encountered in d...\n\nFILE\n    /Users/jortoh/Desktop/Projects/edaviz/edaviz/correlations.py\n\n\n"
    }
   ],
   "source": [
    "from edaviz import correlations as corr\n",
    "help(corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "--- type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(<Nature.NUMBER: 'Number'>,\n <Nature.NUMBER: 'Number'>,\n <Nature.BINARY: 'Binary'>,\n <Nature.BINARY: 'Binary'>)"
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "age_type = corr.donner_type(age)\n",
    "fare_type = corr.donner_type(fare)\n",
    "sex_type = corr.donner_type(sex)\n",
    "survived_type = corr.donner_type(survived)\n",
    "age_type, fare_type, sex_type, survived_type"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "--- correlation qtv x qtv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "78.8799586890295"
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "age_fare_cov = corr.calculer_covariance(age, fare)\n",
    "age_fare_cov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "0.11"
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "age_fare_corr = corr.calculer_correlation_pearson(age, fare)\n",
    "round(age_fare_corr, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(3.362942646303688, 0.0004021266302663973, 0.11232863699941627)"
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "statistique, p_value, coefficient = corr.test_correlation_pearson(age, fare)\n",
    "statistique, p_value, coefficient"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "--- correlation qtv x qlt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(7.533924546397329, 0.28429788404022993, 0.008441051190548542)"
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "age_sex_corr = corr.test_correlation_eta_squared(age, sex)\n",
    "age_sex_corr"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "--- correlation qlt x qlt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([[ 81, 464],\n       [233, 109]])"
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "survived_sex_contingence = corr.calculer_tableau_contingence(survived, sex)\n",
    "survived_sex_contingence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(727.3097247634023, 0.0, 0.9055196672783877)"
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "survived_sex_corr = corr.test_correlation_chi_squared(sex, survived)\n",
    "survived_sex_corr   "
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "--- correlation generique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(3.362942646303688, 0.0004021266302663973, 0.11232863699941627)"
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "age_fare_cor_gen = corr.test_de_correlation(age, fare)\n",
    "age_fare_cor_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(7.533924546397329, 0.28429788404022993, 0.008441051190548542)"
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "age_sex_cor_gen = corr.test_de_correlation(age, sex)\n",
    "age_sex_cor_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(727.3097247634023, 0.0, 0.9055196672783877)"
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "survived_sex_cor_gen = corr.test_de_correlation(survived, sex)\n",
    "survived_sex_cor_gen"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matrice test"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "--- compact form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([[[ 1.00000000e+00,             nan,  1.00000000e+00],\n        [ 1.02159665e+03,  0.00000000e+00,  1.07319322e+00],\n        [ 8.87000000e+02,  4.84212670e-01,  1.00000000e+00],\n        [ 7.27309725e+02,  0.00000000e+00,  9.05519667e-01],\n        [ 3.16179141e+00,  4.26003551e-01,  3.55992730e-03],\n        [ 0.00000000e+00,  1.00000000e+00,  0.00000000e+00],\n        [ 0.00000000e+00,  1.00000000e+00,  0.00000000e+00],\n        [ 6.21596734e+01,  1.00901704e-01,  6.56274493e-02]],\n\n       [[ 1.02159665e+03,  0.00000000e+00,  1.07319322e+00],\n        [ 1.00000000e+00,             nan,  1.00000000e+00],\n        [ 1.77400000e+03,  4.82141003e-01,  1.00000000e+00],\n        [ 1.03150993e+03,  0.00000000e+00,  1.07838763e+00],\n        [ 8.22222711e+01,  1.20883296e-02,  1.56846200e-01],\n        [ 0.00000000e+00,  1.00000000e+00,  0.00000000e+00],\n        [ 0.00000000e+00,  1.00000000e+00,  0.00000000e+00],\n        [ 2.40660418e+02,  4.14659206e-03,  3.52533136e-01]],\n\n       [[ 8.87000000e+02,  4.84212670e-01,  1.00000000e+00],\n        [ 1.77400000e+03,  4.82141003e-01,  1.00000000e+00],\n        [ 1.00000000e+00,             nan,  1.00000000e+00],\n        [ 8.87000000e+02,  4.84212670e-01,  1.00000000e+00],\n        [ 0.00000000e+00,             nan,  1.00000000e+00],\n        [            nan,             nan,  1.00000000e+00],\n        [            nan,             nan,  1.00000000e+00],\n        [-0.00000000e+00,             nan,  1.00000000e+00]],\n\n       [[ 7.27309725e+02,  0.00000000e+00,  9.05519667e-01],\n        [ 1.03150993e+03,  0.00000000e+00,  1.07838763e+00],\n        [ 8.87000000e+02,  4.84212670e-01,  1.00000000e+00],\n        [ 1.00000000e+00,             nan,  1.00000000e+00],\n        [ 7.53392455e+00,  2.84297884e-01,  8.44105119e-03],\n        [ 0.00000000e+00,  1.00000000e+00,  0.00000000e+00],\n        [ 0.00000000e+00,  1.00000000e+00,  0.00000000e+00],\n        [ 3.00224588e+01,  1.44772466e-01,  3.28106251e-02]],\n\n       [[ 3.16179141e+00,  4.26003551e-01,  3.55992730e-03],\n        [ 8.22222711e+01,  1.20883296e-02,  1.56846200e-01],\n        [ 0.00000000e+00,             nan,  1.00000000e+00],\n        [ 7.53392455e+00,  2.84297884e-01,  8.44105119e-03],\n        [ 1.00000000e+00,             nan,  1.00000000e+00],\n        [-8.30169122e+00,  1.00000000e+00, -2.68788718e-01],\n        [-5.28776536e+00,  9.99999922e-01, -1.75003281e-01],\n        [ 3.36294265e+00,  4.02126630e-04,  1.12328637e-01]],\n\n       [[ 0.00000000e+00,  1.00000000e+00,  0.00000000e+00],\n        [ 0.00000000e+00,  1.00000000e+00,  0.00000000e+00],\n        [            nan,             nan,  1.00000000e+00],\n        [ 0.00000000e+00,  1.00000000e+00,  0.00000000e+00],\n        [-8.30169122e+00,  1.00000000e+00, -2.68788718e-01],\n        [ 1.00000000e+00,             nan,  1.00000000e+00],\n        [ 1.82173122e+01,  0.00000000e+00,  5.22230372e-01],\n        [ 4.31142194e+00,  9.02145423e-06,  1.43428420e-01]],\n\n       [[ 0.00000000e+00,  1.00000000e+00,  0.00000000e+00],\n        [ 0.00000000e+00,  1.00000000e+00,  0.00000000e+00],\n        [            nan,             nan,  1.00000000e+00],\n        [ 0.00000000e+00,  1.00000000e+00,  0.00000000e+00],\n        [-5.28776536e+00,  9.99999922e-01, -1.75003281e-01],\n        [ 1.82173122e+01,  0.00000000e+00,  5.22230372e-01],\n        [ 1.00000000e+00,             nan,  1.00000000e+00],\n        [ 5.90294266e+00,  2.54197863e-09,  1.94630681e-01]],\n\n       [[ 6.21596734e+01,  1.00901704e-01,  6.56274493e-02],\n        [ 2.40660418e+02,  4.14659206e-03,  3.52533136e-01],\n        [-0.00000000e+00,             nan,  1.00000000e+00],\n        [ 3.00224588e+01,  1.44772466e-01,  3.28106251e-02],\n        [ 3.36294265e+00,  4.02126630e-04,  1.12328637e-01],\n        [ 4.31142194e+00,  9.02145423e-06,  1.43428420e-01],\n        [ 5.90294266e+00,  2.54197863e-09,  1.94630681e-01],\n        [ 1.00000000e+00,             nan,  1.00000000e+00]]])"
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compacte_matrice = corr.matrice_de_correlation(tableau=unique_data, format_compact=True, calculer_autocorrelation=False)\n",
    "compacte_matrice"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "--- non compacte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([[ 1.        ,  1.07319322,  1.        ,  0.90551967,  0.00355993,\n         0.        ,  0.        ,  0.06562745],\n       [ 1.07319322,  1.        ,  1.        ,  1.07838763,  0.1568462 ,\n         0.        ,  0.        ,  0.35253314],\n       [ 1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n         1.        ,  1.        ,  1.        ],\n       [ 0.90551967,  1.07838763,  1.        ,  1.        ,  0.00844105,\n         0.        ,  0.        ,  0.03281063],\n       [ 0.00355993,  0.1568462 ,  1.        ,  0.00844105,  1.        ,\n        -0.26878872, -0.17500328,  0.11232864],\n       [ 0.        ,  0.        ,  1.        ,  0.        , -0.26878872,\n         1.        ,  0.52223037,  0.14342842],\n       [ 0.        ,  0.        ,  1.        ,  0.        , -0.17500328,\n         0.52223037,  1.        ,  0.19463068],\n       [ 0.06562745,  0.35253314,  1.        ,  0.03281063,  0.11232864,\n         0.14342842,  0.19463068,  1.        ]])"
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stat_mat, p_valeur_mat, coef_mat = corr.matrice_de_correlation(tableau=unique_data, format_compact=False, calculer_autocorrelation=False)\n",
    "coef_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "--- cellules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(0.5, 0.1)"
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha = 0.5\n",
    "tolerance = .1\n",
    "alpha, tolerance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([[False, False, False, False, False,  True,  True, False],\n       [False, False, False, False, False,  True,  True, False],\n       [False, False, False, False, False, False, False, False],\n       [False, False, False, False, False,  True,  True, False],\n       [False, False, False, False, False,  True,  True, False],\n       [ True,  True, False,  True,  True, False, False, False],\n       [ True,  True, False,  True,  True, False, False, False],\n       [False, False, False, False, False, False, False, False]])"
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr.normaliser_significativite_booleen(p_valeur=p_valeur_mat, alpha=alpha, tolerance=tolerance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "[[0, 0, 0, 0, 0, 1.0, 1.0, 0],\n [0, 0, 0, 0, 0, 1.0, 1.0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 1.0, 1.0, 0],\n [0, 0, 0, 0, 0, 0.9999999999999996, 0.9999998439058282, 0],\n [1.0, 1.0, 0, 1.0, 0.9999999999999996, 0, 0, 0],\n [1.0, 1.0, 0, 1.0, 0.9999998439058282, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0]]"
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = lambda x: max(0, (x - alpha) / (1 - alpha))\n",
    "[ list(map(g,l)) for l in p_valeur_mat ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = lambda x: corr.normaliser_significativite_numerique(p_valeur=x, alpha=alpha, tolerance=tolerance, **{ 'valeur_sup': 1.0,\n",
    "                              'valeur_inf': tolerance,\n",
    "                              'pente': 3\n",
    "                            })\n",
    "data_cells = [ list(map(f,l)) for l in p_valeur_mat ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "sign_mat = corr.matrice_de_significativite(p_valeur_mat, alpha, False, tolerance, **{ 'valeur_sup': 1.0,\n",
    "                              'valeur_inf': tolerance,\n",
    "                              'pente': 3\n",
    "                            })"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Help on module edaviz.heatmaps in edaviz:\n\nNAME\n    edaviz.heatmaps\n\nDESCRIPTION\n    Functions to visualize matrices of data.\n    It is a custom version of a Heatmap allowing\n    cells size's customization.\n    It is based on matrix.py in https://github.com/mwaskom/seaborn\n    by Michael L. Waskom\n    ( commit id: https://github.com/mwaskom/seaborn/pull/1830 )\n\nFUNCTIONS\n    custom_cells_heatmap(data, vmin=None, vmax=None, cmap=None, center=None, robust=False, annot=None, fmt='.2g', annot_kws=None, cbar=True, cbar_kws=None, cbar_ax=None, data_cells=None, robust_cells=True, vmin_cells=None, vmax_cells=None, square=False, xticklabels='auto', yticklabels='auto', mask=None, ax=None, ax_kws=None, shape_kws=None, normalize_cells=True, square_shaped_cells=True)\n\nDATA\n    __all__ = ['custom_cells_heatmap']\n\nFILE\n    /Users/jortoh/Desktop/Projects/edaviz/edaviz/heatmaps.py\n\n\n"
    }
   ],
   "source": [
    "from edaviz import heatmaps as hmp\n",
    "help(hmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.55      , 0.55      , 0.55      , 0.55      , 0.55      ,\n        0.99397643, 0.99397643, 0.55      ],\n       [0.55      , 0.55      , 0.55      , 0.55      , 0.55      ,\n        0.99397643, 0.99397643, 0.55      ],\n       [0.55      , 0.55      , 0.55      , 0.55      , 0.55      ,\n        0.55      , 0.55      , 0.55      ],\n       [0.55      , 0.55      , 0.55      , 0.55      , 0.55      ,\n        0.99397643, 0.99397643, 0.55      ],\n       [0.55      , 0.55      , 0.55      , 0.55      , 0.55      ,\n        0.99397643, 0.99397643, 0.55      ],\n       [0.99397643, 0.99397643, 0.55      , 0.99397643, 0.99397643,\n        0.55      , 0.55      , 0.55      ],\n       [0.99397643, 0.99397643, 0.55      , 0.99397643, 0.99397643,\n        0.55      , 0.55      , 0.55      ],\n       [0.55      , 0.55      , 0.55      , 0.55      , 0.55      ,\n        0.55      , 0.55      , 0.55      ]])"
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sign_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'flat'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-84-eda377a67ddd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# rayon a looker\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# mesh à revoir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mhmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcustom_cells_heatmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msign_mat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_cells\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_cells\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvmax\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msquare_shaped_cells\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Desktop/Projects/edaviz/edaviz/heatmaps.py\u001b[0m in \u001b[0;36mcustom_cells_heatmap\u001b[0;34m(data, vmin, vmax, cmap, center, robust, annot, fmt, annot_kws, cbar, cbar_kws, cbar_ax, data_cells, robust_cells, vmin_cells, vmax_cells, square, xticklabels, yticklabels, mask, ax, ax_kws, shape_kws, normalize_cells, square_shaped_cells)\u001b[0m\n\u001b[1;32m    508\u001b[0m     \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 510\u001b[0;31m     \u001b[0mplotter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcbar_ax\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msquare_shaped_cells\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max_kws\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    511\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    512\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Projects/edaviz/edaviz/heatmaps.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, ax, cax, square_shaped_cells, kws)\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m         \u001b[0;31m# Annotate the cells with the formatted values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 480\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_annotate_and_size_cells\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmesh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msquare_shaped_cells\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    481\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Projects/edaviz/edaviz/heatmaps.py\u001b[0m in \u001b[0;36m_annotate_and_size_cells\u001b[0;34m(self, ax, mesh, square_shaped_cells)\u001b[0m\n\u001b[1;32m    362\u001b[0m         for x, y, m, color, annotation, cell_size in zip(xpos.flat, ypos.flat,\n\u001b[1;32m    363\u001b[0m                                                   \u001b[0mmesh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmesh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_facecolors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 364\u001b[0;31m                                                   annot_data.flat, self.plot_cells.flat):\n\u001b[0m\u001b[1;32m    365\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mm\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmasked\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m                 \u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip\u001b[0m \u001b[0;34m(\u001b[0m \u001b[0mcell_size\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvmax_cells\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/edaviz-KtEqFj99/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5177\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5178\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5179\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5181\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'flat'"
     ]
    }
   ],
   "source": [
    "# rayon a looker\n",
    "# mesh à revoir\n",
    "hmp.custom_cells_heatmap(data=sign_mat, data_cells=data_cells, vmin=0, vmax=1, square_shaped_cells=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}